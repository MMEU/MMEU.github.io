<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Modal Embedding and Understanding</title>
    <link rel="stylesheet" href="css/style.css">
    <style>
        #id1{
            width: 1024px;
            height: 300px;
            color: aliceblue;
            background-image: url("resources/image/VCG41N1212079174.jpg");
        }
    </style>
</head>


<body>
    
    <div class="container" id="id1">
        <table border="0" align="center">
            <tr>
                <td width="700" align="center" valign="middle"><h3>ACM MM Asia 2021 Workshop on</h3>
                    <span class="title">Multi-Modal Embedding and Understanding</span></td>
            </tr>
            <tr>
            <td colspan="3" align="center"><h3>Gold Coast, Australia<br>December1-3, 2021</h3>
            </tr>
        </table>
        <!-- <br><p><img src="resources/image/VCG41N1212079174.jpg" width="1000" align="middle"></p> -->
    </div>


</br>
</br>

    <div class="container">
        <h2 class="title3">Overview</h2>
        <div class="overview">
            <p>
                We humans perceive the physical world via multiple ways, e.g., watching, touching, hearing, 
                and so on, which means that we process multi-modal information for environment perception. 
                Multi-modal understanding plays a crucial role in enabling the machine with such ability. 
                Due to its research significance, multi-modal embedding and understanding has gained much 
                research attention and achieved much progress in the past couple of years. The recent 
                advances in deep learning inspire us to explore more and deeper for the multi-modal embedding 
                and understanding, such as self-supervised learning and pre-training in it. In this workshop, 
                we aim to bring together researchers from the field of multimedia to discuss recent research 
                and future directions for multi-modal embedding and understanding, and their applications. 
            </p>

        </div>
    </div>

</br>
</br>

    <div class="container">
        <h2 class="title3">Call for Papers</h2>
        <div class="overview">
            <p>
                Multi-modal understanding are important and fundamental problems in the field of 
                multimodal analysis, which have been attracting much research attention in recent 
                years. Previous works have explored shallow embedding and understanding in many 
                downstream tasks, including cross-modal retrieval, visual navigation, VQA, visual 
                captioning, etc. To encourage researchers to explore new and advanced techniques in 
                this area, we are organizing a workshop on “multi-modal embedding and understanding” 
                with the conjunction of ACM MM Asia 2021, and calling for contributions. The included 
                (but not limited) topics are as follows:
            </p>
            <p>
                <ol>
                    <li>Large-scale pre-training for multi-modal embedding and understanding</li>
                    <li>Self-supervised learning in multi-modal embedding and understanding</li>
                    <li>Semi-supervised learning in multi-modal embedding and understanding</li>
                    <li>Contrastive learning in multi-modal embedding and understanding</li>
                    <li>Interpretability in multi-modal embedding and understanding</li>
                    <li>Interactive multi-modal understanding</li>
                    <li>Trust AI for multi-modal understanding</li>
                    <li>Cross-modal matching and retrieval</li>
                    <li>Cross-modal understanding</li>
                    <li>Multi-modal deep fake generation and detection</li>
                    <li>And other related…</li>
                </ol>
            </p>
        </div>
    </div>

</br>
</br>

    <div class="container">
        <h2 class="title3">Submission Guidelines</h2>
        <div class="overview">
            <p>
                <span class="bold">Submission Site:</span>
            </p>
            <p>
                <a href="https://cmt3.research.microsoft.com/MMASIA2021/">https://cmt3.research.microsoft.com/MMASIA2021/</a>
                <br>
                After signing in the CMT3 as the author, click “<strong>create new submission…</strong>”, 
                please choose "<strong>Workshop2:……</strong>" to submit the paper to the workshop.
            </p>

            <p>
                <span class="bold">Paper Format:</span>
            </p>
            <p>
                Submitted papers (.pdf format) must use the ACM Article Template 
                <a href="https://www.acm.org/publications/proceedings-template">https://www.acm.org/publications/proceedings-template</a>
                . Please remember to add Concepts and Keywords.
            </br></br>
                Please use the template in traditional double-column format to prepare your submissions. 
                For example, word users may use Word Interim Template, and latex users may use 
                sample-sigconf template.
            </p>

            <p>
                <span class="bold">Length:</span>
            </p>
            <p>
                As stated in the CfP, submitted papers may be 6 to 8 pages. Up to two additional pages 
                may be added for references. The reference pages must only contain references. 
                Overlength papers will be rejected without review. Optionally, you may upload 
                supplementary material that complements your submission (100Mb limit).
            </p>

            <p>
                <span class="bold">Blinding:</span>
            </p>
            <p>
                Paper submissions must conform with the "double-blind" review policy. This means that 
                the authors should not know the names of the reviewers of their papers, and reviewers 
                should not know the names of the authors. Please prepare your paper in a way that 
                preserves anonymity of the authors.
            </p>
            <p>
                <ul>
                    <li>Do not put the authors' names under the title.</li>
                    <li>Avoid using phrases such as "our previous work" when referring to earlier publications by the authors.</li>
                    <li>Remove information that may identify the authors in the acknowledgments (e.g., co-workers and grant IDs).</li>
                    <li>Check supplemental material (e.g., titles in the video clips, or supplementary documents) for information that may identify the authors' identities.</li>
                    <li>Avoid providing links to websites that identify the authors.</li>
                </ul>
            </p>
            <p>
                Papers without appropriate blinding will be rejected without review.
            </p>

            <p>
                <span class="bold">Originality:</span>
            </p>
            <p>
                Papers submitted to ACM Multimedia Asia workshops must be the original work of the authors. 
                The may not be simultaneously under review elsewhere. Publications that have been 
                peer-reviewed and have appeared at other conferences or workshops may not be submitted to 
                the workshop. Authors should be aware that ACM has a strict policy with regard to plagiarism 
                and self-plagiarism (<a href="https://www.acm.org/publications/policies/plagiarism">https://www.acm.org/publications/policies/plagiarism</a>). 
                The authors' prior work must be cited appropriately.
            </p>

            <p>
                <span class="bold">Author List:</span>
            </p>
            <p>
                Please ensure that you submit your papers with the full and final list of authors in the 
                correct order. The author list registered for each submission is not allowed to change 
                in any way after the paper submission deadline. (Note that this rule regards the identity 
                of authors, e.g., typos are correctable.)
            </p>

            <p>
                <span class="bold">Proofreading:</span>
            </p>
            <p>
                Please proofread your submission carefully. It is essential that the language use in 
                the paper is clear and correct so that it is easily understandable. (Either US English 
                or UK English spelling conventions are acceptable.)
            </p>

        </div>
    </div>

</br>
</br>

    <div class="container">
        <h2 class="title3">Important dates</h2>
        <div class="overview">
            <p>
                <ul>
                    <li>Paper submission deadline: Oct 19, 2021, 23:59 AoE</li>
                    <li>Notifications of acceptance: Nov 1, 2021</li>
                    <li>Camera-ready submission: Nov 7, 2021, 23:59 AoE</li>
                </ul>
            </p>
        </div>
    </div>

</br>
</br>
        
    <div class="container">
        <h2 class="title3">Organisers</h2>
        <div class="overview">
            <p>
                <ul>
                    <li><span class="bold">Wenguan Wang</span>, ETH Zurich, Switzerland</li>
                    <li><span class="bold">Xiaojun Chang, RMIT</span>, Australia</li>
                    <li><span class="bold">Yanli Ji</span>, University of Electronic Science and Technology of China, China</li>
                    <li><span class="bold">Yi Bin</span>, University of Electronic Science and Technology of China, China</li>
                </ul>
            </p>
        </div>
    </div>

</body>
</html>
